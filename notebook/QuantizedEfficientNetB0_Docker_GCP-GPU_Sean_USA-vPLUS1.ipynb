{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ./ml_training_gcp\n",
    "\n",
    "cat > ./ml_training_gcp/FaceMaskEfficientNet.py <<CODE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "#Data is downloaded into the container via shellscript. We believe this is more efficient\n",
    "traindirectory=\"/app/FaceMask/Train\"\n",
    "testdirectory=\"/app/FaceMask/Test\"\n",
    "validationdirectory=\"/app/FaceMask/Validation\"\n",
    "image_size=224\n",
    "TrainData=keras.utils.image_dataset_from_directory(traindirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "TestData=keras.utils.image_dataset_from_directory(testdirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "ValidationData=keras.utils.image_dataset_from_directory(validationdirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "\n",
    "\n",
    "img_augmentation = keras.models.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n",
    "\n",
    "def build_model(num_classes, IMG_SIZE):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    x = img_augmentation(inputs) #image augmentation within the model. Should this be good practice? Or do we do it inside the map.\n",
    "    #x=inputs\n",
    "    model = keras.applications.EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype='float32', name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "from datetime import datetime\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "#options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "\n",
    "#unbatching as keras.utils.image_dataset_from_directory comes with a default batch\n",
    "TrainData=TrainData.unbatch().with_options(options)\n",
    "TestData=TestData.unbatch().with_options(options)\n",
    "ValidationData=ValidationData.unbatch().with_options(options)\n",
    "\n",
    "#TrainData=TrainData.map(lambda x, y: (img_augmentation(x), y),num_parallel_calls = tf.data.AUTOTUNE)\n",
    "TrainData=TrainData.prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "TestData=TestData.prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "ValidationData=ValidationData.prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "early_stop= tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "with strategy.scope():\n",
    "    model=build_model(2, 224)\n",
    "model.fit(TrainData,\n",
    "        epochs=1,\n",
    "          validation_data=TestData\n",
    "         , callbacks=[tboard_callback,early_stop])\n",
    "model.save(\"FaceMaskEfficientNetModel\")\n",
    "\n",
    "import tensorflow as tf\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('/app/FaceMaskEfficientNetModel')\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "with open('FaceMaskEfficientNetModel.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "    \n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "def evaluate_model(interpreter,model,dataset):\n",
    "    #interpreter = tflite intepreter\n",
    "    #model = full model\n",
    "    dataset=dataset.with_options(options).unbatch().batch(512)\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "  # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    label_digits =[]\n",
    "    full_model_matches=[]\n",
    "    full_model_prediction_digits = []\n",
    "    full_model_label_digits =[]\n",
    "    for i, batch in enumerate(dataset):\n",
    "        #Only Validate for 1 batch\n",
    "        if i==1:\n",
    "            break\n",
    "        print(\"processing batch: \"+str(i+1))\n",
    "        test_images,test_labels=batch\n",
    "        \n",
    "        #evaluate main model\n",
    "        probs=model.predict(test_images)\n",
    "        full_model_predictions=np.argmax(probs, axis=1)\n",
    "        matches=list(np.array(full_model_predictions)==np.array(test_labels))\n",
    "        full_model_matches.extend(matches)\n",
    "        full_model_prediction_digits.extend(full_model_predictions)\n",
    "        full_model_label_digits.extend(test_labels)\n",
    "        \n",
    "        #evaluate quantized model\n",
    "        for n,test_image in enumerate(test_images):\n",
    "            #print('Evaluated on {n} results so far.'.format(n=i))\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "            test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "            interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "            interpreter.invoke()\n",
    "\n",
    "    # Post-processing: remove batch dimension and find the digit with highest\n",
    "    # probability.\n",
    "            output = interpreter.tensor(output_index)\n",
    "            digit = np.argmax(output()[0])\n",
    "            prediction_digits.append(digit)\n",
    "            label_digits.append(test_labels[n])\n",
    "\n",
    "    print('\\n')\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    label_digits=np.array(label_digits)\n",
    "    tflite_accuracy = (prediction_digits == label_digits).mean()\n",
    "    tflite_f1= f1_score(prediction_digits,label_digits)\n",
    "    full_model_accuracy=sum(full_model_matches)/len(full_model_matches)\n",
    "    full_model_f1=f1_score(full_model_prediction_digits,full_model_label_digits)\n",
    "    return tflite_accuracy, full_model_accuracy, tflite_f1,full_model_f1\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "tflite_accuracy, full_model_accuracy, tflite_f1, full_model_f1 = evaluate_model(interpreter,model,ValidationData)\n",
    "print(\"The Full Model Accuracy is: \"+str(full_model_accuracy)+\" and the Quantized Model Accuracy is: \"+str(tflite_accuracy))\n",
    "print(\"The Full Model F1 is: \"+str(full_model_f1)+\" and the Quantized Model F1 is: \"+str(tflite_f1))\n",
    "model_performance={'FullModelAccuracy':full_model_accuracy, \"QuantizedModelAccuracy\":tflite_accuracy, 'AccuracyDifference':tflite_accuracy-full_model_accuracy\n",
    "                  ,'FullModelF1':full_model_f1, \"QuantizedModelF1\":tflite_f1, 'F1Difference':tflite_f1-full_model_f1\n",
    "                  }\n",
    "\n",
    "import json\n",
    "with open('EfficientNetPerformanceComparison.json', 'w') as f:\n",
    "    json.dump(model_performance, f)\n",
    "CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cant Test Training Code Due to GPU Usage requiring complex setup that is easier to do with Docker /n\n",
    "Pull Docker Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from deeplearning-platform-release/tf-gpu.2-8\n",
      "Digest: sha256:5bcd6b34a8c00142040d1561b2a39d5ac13ba576bc8c22548d12d98d37ade168\n",
      "Status: Image is up to date for gcr.io/deeplearning-platform-release/tf-gpu.2-8:latest\n",
      "gcr.io/deeplearning-platform-release/tf-gpu.2-8:latest\n"
     ]
    }
   ],
   "source": [
    "#!docker pull tensorflow/tensorflow:latest-gpu\n",
    "#gcr.io/deeplearning-platform-release/base-cu110\n",
    "#RUN curl -sSL https://sdk.cloud.google.com | bash\n",
    "!docker pull gcr.io/deeplearning-platform-release/tf-gpu.2-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Requirements Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./ml_training_gcp/requirements.txt <<EOF\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Authentication File into Container. This step can be skipped on GCP as it will be auto-auth (and yes this is not safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp daring-hash-348101-9717f041dd58.json ./ml_training_gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Shell Script to Download Data (Note: The entire folder structure will be copied into app. Therefore /app/FaceMask will exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./ml_training_gcp/initialize.sh <<EOF\n",
    "#! /bin/sh\n",
    "gcloud auth activate-service-account --key-file=daring-hash-348101-9717f041dd58.json\n",
    "gsutil -mq cp -r gs://seangoh-smu-mle-usa/FaceMask /app\n",
    "python FaceMaskEfficientNet.py\n",
    "gsutil -mq cp -r /app/FaceMaskEfficientNetModel gs://seangoh-smu-mle-usa/Models/\n",
    "gsutil -q cp /app/FaceMaskEfficientNetModel.tflite gs://seangoh-smu-mle-usa/Models/\n",
    "gsutil -q cp /app/EfficientNetPerformanceComparison.json gs://seangoh-smu-mle-usa/Models/\n",
    "gsutil -mq cp -r /app/logs gs://seangoh-smu-mle-usa/logs/\n",
    "rm -r /app/FaceMask\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Docker File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ./ml_training_gcp/Dockerfile <<EOF\n",
    "FROM gcr.io/deeplearning-platform-release/tf-gpu.2-8\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . /app\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"sh\", \"initialize.sh\"]\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  18.43kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/tf-gpu.2-8\n",
      " ---> cc037125fdd9\n",
      "Step 2/5 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 884c3492a942\n",
      "Step 3/5 : COPY . /app\n",
      " ---> Using cache\n",
      " ---> 60f19f9fd631\n",
      "Step 4/5 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 449e72bd473d\n",
      "Step 5/5 : ENTRYPOINT [\"sh\", \"initialize.sh\"]\n",
      " ---> Using cache\n",
      " ---> dfc94aeb429b\n",
      "Successfully built dfc94aeb429b\n",
      "Successfully tagged masketeers/containerizeml:latest\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "docker build ./ml_training_gcp/ -t masketeers/containerizeml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Container ! docker run masketeers/containerizeml --gpus all -t nvidia/cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated service account credentials for: [591661299323-compute@developer.gserviceaccount.com]\n",
      "2022-06-22 05:43:26.581348: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-06-22 05:43:26.581398: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-22 05:43:26.581430: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (f288b7df2c66): /proc/driver/nvidia/version does not exist\n",
      "2022-06-22 05:43:26.581887: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "2022-06-22 05:43:26.904418: I tensorflow/core/profiler/lib/profiler_session.cc:110] Profiler session initializing.\n",
      "2022-06-22 05:43:26.904461: I tensorflow/core/profiler/lib/profiler_session.cc:125] Profiler session started.\n",
      "2022-06-22 05:43:26.904581: I tensorflow/core/profiler/lib/profiler_session.cc:143] Profiler session tear down.\n",
      "Found 10000 files belonging to 2 classes.\n",
      "Found 992 files belonging to 2 classes.\n",
      "Found 800 files belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 0s 0us/step\n",
      "16719872/16705208 [==============================] - 0s 0us/step\n",
      "2022-06-22 05:43:30.834848: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "2022-06-22 05:43:43.039469: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2022-06-22 05:43:43.306960: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2022-06-22 05:43:43.459829: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2022-06-22 05:43:43.568464: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "2022-06-22 05:43:43.629315: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 102760448 exceeds 10% of free system memory.\n",
      "    157/Unknown - 383s 2s/step - loss: 0.1479 - accuracy: 0.96922022-06-22 05:49:54.906556: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "157/157 [==============================] - 420s 3s/step - loss: 0.1479 - accuracy: 0.9692 - val_loss: 0.0319 - val_accuracy: 0.9950\n",
      "2022-06-22 05:50:39.797689: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-06-22 05:51:13.642403: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-06-22 05:51:13.642472: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-06-22 05:51:13.643658: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /app/FaceMaskEfficientNetModel\n",
      "2022-06-22 05:51:13.733511: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-06-22 05:51:13.733578: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /app/FaceMaskEfficientNetModel\n",
      "2022-06-22 05:51:13.987586: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-06-22 05:51:14.854092: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /app/FaceMaskEfficientNetModel\n",
      "2022-06-22 05:51:15.302923: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 1659270 microseconds.\n",
      "2022-06-22 05:51:16.158078: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-06-22 05:51:17.218535: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/stem_conv/Conv2D because it has fewer than 1024 elements (864).\n",
      "2022-06-22 05:51:17.218619: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block1a_bn/FusedBatchNormV3;EfficientNet/block1a_dwconv/depthwise;EfficientNet/block1a_se_expand/Conv2D because it has fewer than 1024 elements (288).\n",
      "2022-06-22 05:51:17.218632: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block1a_se_reduce/Conv2D because it has fewer than 1024 elements (256).\n",
      "2022-06-22 05:51:17.218658: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block1a_se_expand/Conv2D because it has fewer than 1024 elements (256).\n",
      "2022-06-22 05:51:17.218666: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block1a_project_conv/Conv2D because it has fewer than 1024 elements (512).\n",
      "2022-06-22 05:51:17.218678: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block2a_bn/FusedBatchNormV3;EfficientNet/block2a_dwconv/depthwise;EfficientNet/block2a_se_expand/Conv2D because it has fewer than 1024 elements (864).\n",
      "2022-06-22 05:51:17.218689: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block2a_se_reduce/Conv2D because it has fewer than 1024 elements (384).\n",
      "2022-06-22 05:51:17.218703: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block2a_se_expand/Conv2D because it has fewer than 1024 elements (384).\n",
      "2022-06-22 05:51:17.218722: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block2b_se_reduce/Conv2D because it has fewer than 1024 elements (864).\n",
      "2022-06-22 05:51:17.218742: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block2b_se_expand/Conv2D because it has fewer than 1024 elements (864).\n",
      "2022-06-22 05:51:17.218759: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block3a_se_reduce/Conv2D because it has fewer than 1024 elements (864).\n",
      "2022-06-22 05:51:17.218779: I tensorflow/lite/tools/optimize/quantize_weights.cc:225] Skipping quantization of tensor EfficientNet/block3a_se_expand/Conv2D because it has fewer than 1024 elements (864).\n",
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2022-06-22 05:51:19.677479: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_9\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"PrefetchDataset/_8\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_slice_batch_indices_128143\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:85\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: 32\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_INT64\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2022-06-22 05:51:19.751913: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "processing batch: 1\n",
      "\n",
      "\n",
      "The Full Model Accuracy is: 0.994140625 and the Quantized Model Accuracy is: 0.9921875\n",
      "The Full Model F1 is: 0.9937888198757764 and the Quantized Model F1 is: 0.9917012448132779\n"
     ]
    }
   ],
   "source": [
    "! docker run masketeers/containerizeml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run in Terminal\n",
    "#sudo usermod -a -G docker ${USER}\n",
    "#gcloud auth configure-docker asia-southeast1-docker.pkg.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activated service account credentials for: [591661299323-compute@developer.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "!gcloud auth activate-service-account --key-file=daring-hash-348101-9717f041dd58.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  18.43kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/tf-gpu.2-8\n",
      " ---> cc037125fdd9\n",
      "Step 2/5 : WORKDIR /app\n",
      " ---> Using cache\n",
      " ---> 884c3492a942\n",
      "Step 3/5 : COPY . /app\n",
      " ---> Using cache\n",
      " ---> 60f19f9fd631\n",
      "Step 4/5 : RUN pip install -r requirements.txt\n",
      " ---> Using cache\n",
      " ---> 449e72bd473d\n",
      "Step 5/5 : ENTRYPOINT [\"sh\", \"initialize.sh\"]\n",
      " ---> Using cache\n",
      " ---> dfc94aeb429b\n",
      "Successfully built dfc94aeb429b\n",
      "Successfully tagged us-east1-docker.pkg.dev/daring-hash-348101/smu-mle-usa/efficientnettrain:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build ./ml_training_gcp/ -t us-east1-docker.pkg.dev/daring-hash-348101/smu-mle-usa/efficientnettrain:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [us-east1-docker.pkg.dev/daring-hash-348101/smu-mle-usa/efficientnettrain]\n",
      "\n",
      "\u001b[1Beb1967b2: Preparing \n",
      "\u001b[1B02f7ac52: Preparing \n",
      "\u001b[1B95a9cd9c: Preparing \n",
      "\u001b[1Bb3120056: Preparing \n",
      "\u001b[1B53b734c4: Preparing \n",
      "\u001b[1Bb4a993bf: Preparing \n",
      "\u001b[1Ba0734f1b: Preparing \n",
      "\u001b[1B39fb5680: Preparing \n",
      "\u001b[1B6da164cd: Preparing \n",
      "\u001b[1B22d8d85c: Preparing \n",
      "\u001b[1Bb01c5179: Preparing \n",
      "\u001b[1Be696ff5b: Preparing \n",
      "\u001b[1B43fff4a9: Preparing \n",
      "\u001b[1B86de6044: Preparing \n",
      "\u001b[1B8d193daf: Preparing \n",
      "\u001b[1B188023c9: Preparing \n",
      "\u001b[1B0496c2b3: Preparing \n",
      "\u001b[1Bdc387b12: Preparing \n",
      "\u001b[1B257dc2e4: Preparing \n",
      "\u001b[1B54032850: Preparing \n",
      "\u001b[1B951137ff: Preparing \n",
      "\u001b[1Bc25e1d03: Preparing \n",
      "\u001b[1B01bb0f15: Preparing \n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B6f75faab: Preparing \n",
      "\u001b[1Bac543081: Preparing \n",
      "\u001b[1Bc4c62eef: Preparing \n",
      "\u001b[1Ba71261c7: Preparing \n",
      "\u001b[1Bba43cdbe: Preparing \n",
      "\u001b[1B942867a5: Preparing \n",
      "\u001b[1Bfe6d10a9: Preparing \n",
      "\u001b[1B91182163: Preparing \n",
      "\u001b[1B6c5bb65c: Preparing \n",
      "\u001b[1B550a3bbe: Preparing \n",
      "\u001b[1Bedc62fb3: Layer already exists \u001b[29A\u001b[2K\u001b[25A\u001b[2K\u001b[17A\u001b[2K\u001b[11A\u001b[2K\u001b[3A\u001b[2Klatest: digest: sha256:c8bedeb092902a962b825b3b1021cbcb0c24b398863b847ecd4381aa3f802daf size: 7665\n"
     ]
    }
   ],
   "source": [
    "!docker push us-east1-docker.pkg.dev/daring-hash-348101/smu-mle-usa/efficientnettrain:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Does GCSFuse work better or copy with gsutils for image dataset\n",
    "#Cannot test gpu training with python.py but requires a gpu container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
