{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                       TAG       IMAGE ID       CREATED        SIZE\n",
      "asia-southeast1-docker.pkg.dev/vertexai-intro-347706/mle-docker/containerizeml   latest    af513a508317   4 weeks ago    1.35GB\n",
      "teyanglau/containerizeml                                                         latest    af513a508317   4 weeks ago    1.35GB\n",
      "hello-world                                                                      latest    feb5d9fea6a5   8 months ago   13.3kB\n"
     ]
    }
   ],
   "source": [
    "! docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p ../dockerTYtry/src\n",
    "\n",
    "cat > ../dockerTYtry/src/FaceMaskEfficientNet.py <<CODE\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import os\n",
    "from keras import layers\n",
    "\n",
    "print(os.getcwd())\n",
    "print(os.listdir())\n",
    "\n",
    "#Data is downloaded into the container via shellscript. We believe this is more efficient\n",
    "traindirectory=\"/app/data/Train_Small\"\n",
    "testdirectory=\"/app/data/Test_Small\"\n",
    "image_size=224\n",
    "TrainData=keras.utils.image_dataset_from_directory(traindirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "TestData=keras.utils.image_dataset_from_directory(testdirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "\n",
    "img_augmentation = keras.models.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n",
    "\n",
    "def build_model(num_classes, IMG_SIZE):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    x = img_augmentation(inputs) #image augmentation within the model. Should this be good practice? Or do we do it inside the map.\n",
    "    model = keras.applications.EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "    \n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype='float32', name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def normalize_img(image, label):\n",
    "    return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "from datetime import datetime\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "TrainData.map(normalize_img).prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "TestData.map(normalize_img).prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    model=build_model(2, 224)\n",
    "model.fit(TrainData,\n",
    "        epochs=1,\n",
    "          validation_data=TestData\n",
    "         , callbacks=[tboard_callback])\n",
    "model.save(\"FaceMaskEfficientNetModel\")\n",
    "CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python ../dockerTYtry/src/FaceMaskEfficientNet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cant Test Training Code Due to GPU Usage requiring complex setup that is easier to do with Docker /n\n",
    "Pull Docker Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Requirements Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ../dockerTYtry/requirements.txt <<EOF\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy Authentication File into Container. This step can be skipped on GCP as it will be auto-auth (and yes this is not safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cp daring-hash-348101-2f4dd5ea462e.json ./ml_training_gcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Shell Script to Download Data (Note: The entire folder structure will be copied into app. Therefore /app/FaceMask will exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ../dockerTYtry/src/initialize.sh <<EOF\n",
    "#! /bin/sh\n",
    "gsutil -mq cp -r gs://face-mask-dataset-smu/ /app/data/\n",
    "python ./src/FaceMaskEfficientNet.py\n",
    "gsutil -mq cp -r /app/FaceMaskEfficientNetModel gs://face-mask-dataset-smu/Models/\n",
    "gsutil -mq cp -r /app/logs gs://face-mask-dataset-smu/logs/\n",
    "rm -r /app/data\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Docker File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat > ../dockerTYtry/Dockerfile <<EOF\n",
    "FROM gcr.io/deeplearning-platform-release/tf-gpu.2-8\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "COPY . /app\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "ENTRYPOINT [\"sh\", \"initialize.sh\"]\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#2 [internal] load .dockerignore\n",
      "#2 sha256:fe11ce61aa789f42602c60816d12173f7519e658c342fdbdffa99df3bb9cc8ce\n",
      "#2 transferring context: 2B 0.0s done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 sha256:3996cb2a1495480f5b9d9777fe182edf1196630cc89955996c82dfd820be3767\n",
      "#1 transferring dockerfile: 197B 0.0s done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#3 [internal] load metadata for gcr.io/deeplearning-platform-release/tf-gpu.2-8:latest\n",
      "#3 sha256:38885463e846526fc0e8d585f14202d74ae98ebd5f0945b54469e2c8de63547b\n",
      "#3 DONE 0.7s\n",
      "\n",
      "#7 [1/4] FROM gcr.io/deeplearning-platform-release/tf-gpu.2-8@sha256:5bcd6b34a8c00142040d1561b2a39d5ac13ba576bc8c22548d12d98d37ade168\n",
      "#7 sha256:b7f6c9254a3ddcf119006fe5e72cb779554d7200fb9acec6f721edd0d9d7159b\n",
      "#7 DONE 0.0s\n",
      "\n",
      "#8 [internal] load build context\n",
      "#8 sha256:2da78534fb08d14cc6e4177cd68809abdf93392b597ae788ebb403df0e298383\n",
      "#8 transferring context: 607B 0.0s done\n",
      "#8 DONE 0.0s\n",
      "\n",
      "#4 [2/4] WORKDIR /app\n",
      "#4 sha256:37a2a63ecebb33c332ba2a3578fe6e1a584a74e3b696a9fbfeefe01a531e2dc8\n",
      "#4 CACHED\n",
      "\n",
      "#5 [3/4] COPY . /app\n",
      "#5 sha256:c42f268c3dd9e7f1e0e98bd1c391479e1ca65263c515534ded7907c30a0e7071\n",
      "#5 DONE 0.1s\n",
      "\n",
      "#6 [4/4] RUN pip install -r requirements.txt\n",
      "#6 sha256:a4e005bf126b18afaa7a6f70455ea16b88f10d6d215e020c2d52ca2f9aeaafd7\n",
      "#6 3.781 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#6 DONE 4.1s\n",
      "\n",
      "#9 exporting to image\n",
      "#9 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00\n",
      "#9 exporting layers 0.1s done\n",
      "#9 writing image sha256:451191c667c0efd041a8500c7dcfe533b915592ec908df041ed83996d7699abe done\n",
      "#9 naming to docker.io/teyanglau/facemask-ml-train done\n",
      "#9 DONE 0.1s\n",
      "\n",
      "Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "docker build ../dockerTYtry/ -t teyanglau/facemask-ml-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                       TAG       IMAGE ID       CREATED         SIZE\n",
      "teyanglau/facemask-ml-train                                                      latest    2230858b3e63   4 seconds ago   15.1GB\n",
      "asia-southeast1-docker.pkg.dev/vertexai-intro-347706/mle-docker/containerizeml   latest    af513a508317   4 weeks ago     1.35GB\n",
      "teyanglau/containerizeml                                                         latest    af513a508317   4 weeks ago     1.35GB\n",
      "hello-world                                                                      latest    feb5d9fea6a5   8 months ago    13.3kB\n"
     ]
    }
   ],
   "source": [
    "! docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run on terminal\n",
    "# install, authenticate and init gcloud\n",
    "# https://cloud.google.com/sdk/docs/install#deb \n",
    "# https://cloud.google.com/sdk/docs/initializing\n",
    "\n",
    "gcloud auth login --no-launch-browser # gcloud init --console-only\n",
    "sudo usermod -a -G docker ${USER} # not needed for MacOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68342d1c4a48094469edef9f9554beb5e1a3b5fe73fb389c236252c03f11d3ac"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
