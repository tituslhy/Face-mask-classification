{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01a66e2d-9d60-4d84-af04-7b914cd2eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 files belonging to 2 classes.\n",
      "Found 992 files belonging to 2 classes.\n",
      "Found 800 files belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.fit(TrainData,\\n        epochs=1,\\n          validation_data=TestData\\n         , callbacks=[tboard_callback,early_stop])\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import os\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "#Data is downloaded into the container via shellscript. We believe this is more efficient\n",
    "traindirectory=\"./archive/FaceMaskDataset/Train\"\n",
    "testdirectory=\"./archive/FaceMaskDataset/Test\"\n",
    "validationdirectory=\"./archive/FaceMaskDataset/Validation\"\n",
    "image_size=224\n",
    "TrainData=keras.utils.image_dataset_from_directory(traindirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "TestData=keras.utils.image_dataset_from_directory(testdirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "ValidationData=keras.utils.image_dataset_from_directory(validationdirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "\n",
    "def normalization(image, label):\n",
    "    return tf.cast(image, tf.float32)/255., label\n",
    "\n",
    "TrainData=TrainData.map(normalization)\n",
    "TestData=TestData.map(normalization)\n",
    "\n",
    "from datetime import datetime\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "early_stop= tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "\n",
    "#with strategy.scope():\n",
    "#    model=build_model(2, 224)\n",
    "'''\n",
    "model.fit(TrainData,\n",
    "        epochs=1,\n",
    "          validation_data=TestData\n",
    "         , callbacks=[tboard_callback,early_stop])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffe760c-ab62-45ac-ac7f-833f841f7b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 40s 112ms/step - loss: 0.1645 - accuracy: 0.9458 - val_loss: 0.3680 - val_accuracy: 0.8851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d70977db80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(64, activation='relu'))\n",
    "model2.add(layers.Dense(2, activation=\"softmax\", dtype='float32'))\n",
    "model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "model2.fit(TrainData,\n",
    "        epochs=1,\n",
    "          validation_data=TestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a93cd29-0ea3-4ca2-ba33-2f179310fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "313/313 [==============================] - 58s 178ms/step - loss: 0.0687 - accuracy: 0.9758 - val_loss: 0.0623 - val_accuracy: 0.9819\n",
      "Epoch 2/2\n",
      "313/313 [==============================] - 56s 178ms/step - loss: 0.0724 - accuracy: 0.9765 - val_loss: 0.1411 - val_accuracy: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d7d58591f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model2)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.fit(TrainData, epochs=2, validation_data=TestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd733695-9535-4cbe-9ce0-1977ea91713c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
