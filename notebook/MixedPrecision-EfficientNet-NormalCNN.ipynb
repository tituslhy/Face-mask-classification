{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d917e9e-5532-42d4-8177-f7e04c7e014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: GeForce GTX 1650 with Max-Q Design, compute capability 7.5\n",
      "Found 10000 files belonging to 2 classes.\n",
      "Found 992 files belonging to 2 classes.\n",
      "Found 800 files belonging to 2 classes.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "157/157 [==============================] - 148s 591ms/step - loss: nan - accuracy: 0.9874 - val_loss: nan - val_accuracy: 0.5131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f160b5cdf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "#from PIL import Image\n",
    "import os\n",
    "from keras import layers\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "#Data is downloaded into the container via shellscript. We believe this is more efficient\n",
    "traindirectory=\"./archive/FaceMaskDataset/Train\"\n",
    "testdirectory=\"./archive/FaceMaskDataset/Test\"\n",
    "validationdirectory=\"./archive/FaceMaskDataset/Validation\"\n",
    "image_size=224\n",
    "TrainData=keras.utils.image_dataset_from_directory(traindirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "TestData=keras.utils.image_dataset_from_directory(testdirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "ValidationData=keras.utils.image_dataset_from_directory(validationdirectory, class_names=[\"WithoutMask\",\"WithMask\"], image_size=(image_size,image_size))\n",
    "\n",
    "img_augmentation = keras.models.Sequential(\n",
    "    [\n",
    "        layers.RandomRotation(factor=0.15),\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        layers.RandomFlip(),\n",
    "        layers.RandomContrast(factor=0.1),\n",
    "    ],\n",
    "    name=\"img_augmentation\",\n",
    ")\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.Resizing(image_size, image_size),\n",
    "  layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "\n",
    "def cast_img(image, label):\n",
    "    return tf.cast(image, tf.float16), label\n",
    "\n",
    "def build_model(num_classes, IMG_SIZE):\n",
    "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "\n",
    "    #x = img_augmentation(inputs) #image augmentation within the model. Should this be good practice? Or do we do it inside the map.\n",
    "    x=inputs\n",
    "    model = keras.applications.EfficientNetB0(include_top=False, input_tensor=x, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", dtype='float32', name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "#options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
    "\n",
    "\n",
    "#unbatching as keras.utils.image_dataset_from_directory comes with a default batch\n",
    "TrainData=TrainData.unbatch().with_options(options)\n",
    "TestData=TestData.unbatch().with_options(options)\n",
    "ValidationData=ValidationData.unbatch().with_options(options)\n",
    "\n",
    "#TrainData=TrainData.map(lambda x, y: (img_augmentation(x), y),num_parallel_calls = tf.data.AUTOTUNE)\n",
    "TrainData=TrainData.prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "TestData=TestData.prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "ValidationData=ValidationData.prefetch(tf.data.AUTOTUNE).batch(64*strategy.num_replicas_in_sync)\n",
    "\n",
    "logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "early_stop= tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')\n",
    "with strategy.scope():\n",
    "    model=build_model(2, 224)\n",
    "model.fit(TrainData,\n",
    "        epochs=1,\n",
    "          validation_data=TestData\n",
    "         , callbacks=[tboard_callback,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9afaf319-37be-4216-bd37-30f7af9adaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 47s 298ms/step - loss: nan - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, 0.5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EFFICIENT NET\n",
    "model.evaluate(TrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb0b24d0-a3ad-429b-9749-35e1252aafa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seang\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend.py:4906: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 86s 372ms/step - loss: 66.1441 - accuracy: 0.8679 - val_loss: 0.1867 - val_accuracy: 0.9587\n",
      "Epoch 2/5\n",
      "157/157 [==============================] - 49s 309ms/step - loss: 0.1294 - accuracy: 0.9481 - val_loss: 0.1122 - val_accuracy: 0.9567\n",
      "Epoch 3/5\n",
      "157/157 [==============================] - 49s 308ms/step - loss: 0.0691 - accuracy: 0.9710 - val_loss: 0.1028 - val_accuracy: 0.9728\n",
      "Epoch 4/5\n",
      "157/157 [==============================] - 50s 315ms/step - loss: 0.0712 - accuracy: 0.9774 - val_loss: 0.1046 - val_accuracy: 0.9657\n",
      "Epoch 5/5\n",
      "157/157 [==============================] - 49s 308ms/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 0.1330 - val_accuracy: 0.9597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1e7d1b340>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NORMAL MODEL\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "with strategy.scope():\n",
    "    model2 = models.Sequential()\n",
    "    model2.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "    model2.add(layers.MaxPooling2D((2, 2)))\n",
    "    model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model2.add(layers.MaxPooling2D((2, 2)))\n",
    "    model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model2.add(layers.Flatten())\n",
    "    model2.add(layers.Dense(64, activation='relu'))\n",
    "    model2.add(layers.Dense(2, activation=\"softmax\", dtype='float32'))\n",
    "    model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(TrainData,\n",
    "        epochs=5,\n",
    "          validation_data=TestData\n",
    "         , callbacks=[tboard_callback,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800642a-977c-4372-8174-169090091441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901f9e2-f5a3-49a7-bb84-ce723ccc8e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d7415-80bc-4fc0-bf69-2df64573b586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
